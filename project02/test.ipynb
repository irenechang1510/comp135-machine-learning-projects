{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "x_train_df = pd.read_csv('data_reviews/x_train.csv')\n",
    "y_train_df = pd.read_csv('data_reviews/y_train.csv')\n",
    "\n",
    "tr_text_list = x_train_df['text'].values.tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Special characters and punctuation\n",
    "df = x_train_df.copy()\n",
    "punc_list = list(\"?:!.,;()\")\n",
    "df[\"text_1\"] = df[\"text\"].str.replace(\"\\n\", \"\")\n",
    "df[\"text_1\"] = df[\"text_1\"].str.replace('\"', \"\")\n",
    "df[\"text_1\"] = df[\"text_1\"].str.replace(\"'s\", \"\")\n",
    "for punc in punc_list:\n",
    "    df[\"text_1\"] = df[\"text_1\"].str.replace(punc, \"\")\n",
    "    \n",
    "#lowering cases\n",
    "df[\"text_1\"] = df[\"text_1\"].str.lower()\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  website_name                                               text  \\\n",
       "0       amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1       amazon                       THAT one didn't work either.   \n",
       "2       amazon                                 Waste of 13 bucks.   \n",
       "3       amazon  Product is useless, since it does not have eno...   \n",
       "4       amazon  None of the three sizes they sent with the hea...   \n",
       "\n",
       "                                              text_1  \n",
       "0  oh and i forgot to also mention the weird colo...  \n",
       "1                        that one didn't work either  \n",
       "2                                  waste of 13 bucks  \n",
       "3  product is useless since it does not have enou...  \n",
       "4  none of the three sizes they sent with the hea...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>that one didn't work either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>waste of 13 bucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>product is useless since it does not have enou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three sizes they sent with the hea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#stemming and lemmatization\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    if word == '':\n",
    "        return ''\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['text_1']\n",
    "    text_words = text.split(\" \")\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        pos = get_wordnet_pos(word)\n",
    "        if pos != '':\n",
    "            lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=pos))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "\n",
    "df['text_2'] = lemmatized_text_list\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  website_name                                               text  \\\n",
       "0       amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1       amazon                       THAT one didn't work either.   \n",
       "2       amazon                                 Waste of 13 bucks.   \n",
       "3       amazon  Product is useless, since it does not have eno...   \n",
       "4       amazon  None of the three sizes they sent with the hea...   \n",
       "\n",
       "                                              text_1  \\\n",
       "0  oh and i forgot to also mention the weird colo...   \n",
       "1                        that one didn't work either   \n",
       "2                                  waste of 13 bucks   \n",
       "3  product is useless since it does not have enou...   \n",
       "4  none of the three sizes they sent with the hea...   \n",
       "\n",
       "                                              text_2  \n",
       "0  oh and i forgot to also mention the weird colo...  \n",
       "1                        that one didn't work either  \n",
       "2                                   waste of 13 buck  \n",
       "3  product be useless since it do not have enough...  \n",
       "4  none of the three size they sent with the head...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>that one didn't work either</td>\n",
       "      <td>that one didn't work either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>waste of 13 bucks</td>\n",
       "      <td>waste of 13 buck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>product is useless since it does not have enou...</td>\n",
       "      <td>product be useless since it do not have enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three size they sent with the head...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#remove numbers\n",
    "pattern = r'[0-9]'\n",
    "remove_number = []\n",
    "for text in df[\"text_2\"].tolist():\n",
    "    remove_number.append(re.sub(pattern, '', text))\n",
    "    \n",
    "df[\"text_3\"] = remove_number\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     website_name                                               text  \\\n",
       "0          amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1          amazon                       THAT one didn't work either.   \n",
       "2          amazon                                 Waste of 13 bucks.   \n",
       "3          amazon  Product is useless, since it does not have eno...   \n",
       "4          amazon  None of the three sizes they sent with the hea...   \n",
       "...           ...                                                ...   \n",
       "2395         yelp  The sweet potato fries were very good and seas...   \n",
       "2396         yelp  I could eat their bruschetta all day it is dev...   \n",
       "2397         yelp                               Ambience is perfect.   \n",
       "2398         yelp  We ordered the duck rare and it was pink and t...   \n",
       "2399         yelp       Service was good and the company was better!   \n",
       "\n",
       "                                                 text_1  \\\n",
       "0     oh and i forgot to also mention the weird colo...   \n",
       "1                           that one didn't work either   \n",
       "2                                     waste of 13 bucks   \n",
       "3     product is useless since it does not have enou...   \n",
       "4     none of the three sizes they sent with the hea...   \n",
       "...                                                 ...   \n",
       "2395  the sweet potato fries were very good and seas...   \n",
       "2396  i could eat their bruschetta all day it is devine   \n",
       "2397                                ambience is perfect   \n",
       "2398  we ordered the duck rare and it was pink and t...   \n",
       "2399        service was good and the company was better   \n",
       "\n",
       "                                                 text_2  \\\n",
       "0     oh and i forgot to also mention the weird colo...   \n",
       "1                           that one didn't work either   \n",
       "2                                      waste of 13 buck   \n",
       "3     product be useless since it do not have enough...   \n",
       "4     none of the three size they sent with the head...   \n",
       "...                                                 ...   \n",
       "2395  the sweet potato fry be very good and season well   \n",
       "2396  i could eat their bruschetta all day it be devine   \n",
       "2397                                ambience be perfect   \n",
       "2398  we order the duck rare and it be pink and tend...   \n",
       "2399            service be good and the company be well   \n",
       "\n",
       "                                                 text_3  \n",
       "0     oh and i forgot to also mention the weird colo...  \n",
       "1                           that one didn't work either  \n",
       "2                                        waste of  buck  \n",
       "3     product be useless since it do not have enough...  \n",
       "4     none of the three size they sent with the head...  \n",
       "...                                                 ...  \n",
       "2395  the sweet potato fry be very good and season well  \n",
       "2396  i could eat their bruschetta all day it be devine  \n",
       "2397                                ambience be perfect  \n",
       "2398  we order the duck rare and it be pink and tend...  \n",
       "2399            service be good and the company be well  \n",
       "\n",
       "[2400 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>text_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>that one didn't work either</td>\n",
       "      <td>that one didn't work either</td>\n",
       "      <td>that one didn't work either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>waste of 13 bucks</td>\n",
       "      <td>waste of 13 buck</td>\n",
       "      <td>waste of  buck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>product is useless since it does not have enou...</td>\n",
       "      <td>product be useless since it do not have enough...</td>\n",
       "      <td>product be useless since it do not have enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three sizes they sent with the hea...</td>\n",
       "      <td>none of the three size they sent with the head...</td>\n",
       "      <td>none of the three size they sent with the head...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The sweet potato fries were very good and seas...</td>\n",
       "      <td>the sweet potato fries were very good and seas...</td>\n",
       "      <td>the sweet potato fry be very good and season well</td>\n",
       "      <td>the sweet potato fry be very good and season well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>yelp</td>\n",
       "      <td>I could eat their bruschetta all day it is dev...</td>\n",
       "      <td>i could eat their bruschetta all day it is devine</td>\n",
       "      <td>i could eat their bruschetta all day it be devine</td>\n",
       "      <td>i could eat their bruschetta all day it be devine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Ambience is perfect.</td>\n",
       "      <td>ambience is perfect</td>\n",
       "      <td>ambience be perfect</td>\n",
       "      <td>ambience be perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>yelp</td>\n",
       "      <td>We ordered the duck rare and it was pink and t...</td>\n",
       "      <td>we ordered the duck rare and it was pink and t...</td>\n",
       "      <td>we order the duck rare and it be pink and tend...</td>\n",
       "      <td>we order the duck rare and it be pink and tend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Service was good and the company was better!</td>\n",
       "      <td>service was good and the company was better</td>\n",
       "      <td>service be good and the company be well</td>\n",
       "      <td>service be good and the company be well</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "list_columns = [\"website_name\", \"text_3\"]\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean[list_columns]\n",
    "df_clean = df_clean.rename(columns={'text_3': 'text'})\n",
    "df_clean.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  website_name                                               text\n",
       "0       amazon  oh and i forgot to also mention the weird colo...\n",
       "1       amazon                        that one didn't work either\n",
       "2       amazon                                     waste of  buck\n",
       "3       amazon  product be useless since it do not have enough...\n",
       "4       amazon  none of the three size they sent with the head..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>oh and i forgot to also mention the weird colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>that one didn't work either</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>waste of  buck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>product be useless since it do not have enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>none of the three size they sent with the head...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker(distance=4)\n",
    "list_words = []\n",
    "for index, txt in enumerate(df_clean.text):\n",
    "    words = spell.split_words(txt)\n",
    "    list_words = [spell.correction(word) for word in words]\n",
    "    df_clean.loc[index, 'text'] = ' '.join(list_words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = list(stopwords.words('english'))\n",
    "to_remove = ['against', 'into', 'above', 'below', 'up', 'down', 'on', 'off', 'again', 'few', 'more', 'most', 'no', 'not', 'only', 'same']\n",
    "for word in to_remove:\n",
    "    stop_words.remove(word)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/irenechang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 2, stop_words = stop_words)\n",
    "vectors = vectorizer.fit_transform(df_clean['text'].values.tolist())\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "\n",
    "# all_important_words3 = []\n",
    "# for index, item in enumerate(denselist3):\n",
    "#     scores3 = {feature: tfidf for feature, tfidf in zip(feature_names3, item)}\n",
    "#     sorted_words3 = sorted(scores3.items(), key=lambda x: x[1], reverse=True)\n",
    "#     for word, score in sorted_words3: \n",
    "#         if score > 2:\n",
    "#             all_important_words3.append((word, score))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "vectorizer2 = TfidfVectorizer(min_df = 2)\n",
    "vectors2 = vectorizer2.fit_transform(df_clean['text'].values.tolist())\n",
    "feature_names2 = vectorizer2.get_feature_names()\n",
    "dense2 = vectors2.todense()\n",
    "denselist2 = dense2.tolist()\n",
    "\n",
    "feature_names2 = vectorizer2.get_feature_names()\n",
    "trainset2 = pd.DataFrame(denselist2, columns=feature_names2)\n",
    "\n",
    "# with stopwords\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(trainset2, y_train_df['is_positive_sentiment'], test_size=0.33, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "trainset = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "# without stopwords\n",
    "x_train, x_test, y_train, y_test = train_test_split(trainset, y_train_df['is_positive_sentiment'], test_size=0.33, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "trainset2.to_csv('important_words.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LR TFIDF Unigram Without Stopwords (currently best model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# logistic regression with stopwords\n",
    "# 0.9347014925373134\n",
    "# 0.7714646464646465"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# logistic regression without stopwords\n",
    "base_lr = LogisticRegression()\n",
    "base_lr.fit(x_train, y_train)\n",
    "print(base_lr.score(x_train, y_train))\n",
    "print(base_lr.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9371890547263682\n",
      "0.7992424242424242\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "param_grid = {\"C\":np.logspace(-3,3,10), \"max_iter\":[50, 150, 250, 350, 450, 500]}\n",
    "tune_lr = LogisticRegression()\n",
    "grid_search = RandomizedSearchCV(tune_lr, param_distributions = param_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1, n_iter=50)\n",
    "grid_search.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03]),\n",
       "                                        'max_iter': [50, 150, 250, 350, 450,\n",
       "                                                     500]},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "print('Best parameters found:\\n', grid_search.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % grid_search.score(x_train, y_train))\n",
    "print(\" Test accuracy: %.4f\" % grid_search.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'max_iter': 250, 'C': 2.154434690031882}\n",
      "Train accuracy: 0.9515\n",
      " Test accuracy: 0.8056\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# print('Best parameters found:\\n', grid_search.best_params_)\n",
    "# print(\"Train accuracy: %.4f\" % grid_search.score(x_train2, y_train2))\n",
    "# print(\" Test accuracy: %.4f\" % grid_search.score(x_test2, y_test2))\n",
    "# Best parameters found:\n",
    "#  {'max_iter': 500, 'C': 2.154434690031882}\n",
    "# Train accuracy: 0.9527\n",
    "#  Test accuracy: 0.7866"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "\n",
    "def plot_accuracy_and_logLoss(range, train_acc, test_acc, train_logLoss, test_logLoss):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "    ax[0].plot(range, train_acc, color=\"red\", label=\"train\")\n",
    "    ax[0].plot(range, test_acc, color=\"blue\", label=\"test\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('C values')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[1].plot(range, train_logLoss, color=\"red\", label=\"train\")\n",
    "    ax[1].plot(range, test_logLoss, color=\"blue\", label=\"test\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('C values')\n",
    "    ax[1].set_ylabel('Log loss')\n",
    "    plt.show()\n",
    "\n",
    "def examine_Cs(data_train, label_train):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_logLoss = []\n",
    "    test_logLoss = []\n",
    "    for c in np.logspace(-1,1,10):\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "        train_acc_fold = []\n",
    "        test_acc_fold = []\n",
    "        train_logLoss_fold = []\n",
    "        test_logLoss_fold = []\n",
    "        for train_index, test_index in kf.split(data_train):\n",
    "            X_train, X_test = data_train.loc[train_index], data_train.loc[test_index]\n",
    "            y_train, y_test = label_train[train_index], label_train[test_index]\n",
    "            lr = LogisticRegression(C = c)\n",
    "            lr.fit(X_train, y_train)\n",
    "\n",
    "            train_acc_fold.append(lr.score(X_train, y_train))\n",
    "            test_acc_fold.append(lr.score(X_test, y_test))\n",
    "            train_logLoss_fold.append(log_loss(y_train, lr.predict(X_train)))\n",
    "            test_logLoss_fold.append(log_loss(y_test, lr.predict(X_test)))\n",
    "        print(\"C value: %0.3f\" % c)\n",
    "        print(\"Training accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in train_acc_fold), \"Mean: \", '%0.3f'%np.mean(train_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_acc_fold))\n",
    "        print(\"Testing accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in test_acc_fold), \"Mean: \", '%0.3f'%np.mean(test_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_acc_fold))\n",
    "        print(\"Training log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in train_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(train_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_logLoss_fold))\n",
    "        print(\"Testing log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in test_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(test_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_logLoss_fold), \"\\n\")\n",
    "        \n",
    "        train_acc.append(sum(train_acc_fold)/4)\n",
    "        test_acc.append(sum(test_acc_fold)/4)\n",
    "        train_logLoss.append(sum(train_logLoss_fold)/4)\n",
    "        test_logLoss.append(sum(test_logLoss_fold)/4)\n",
    "    # plot_accuracy_and_logLoss(np.logspace(-1,1,10), train_acc, test_acc, train_logLoss, test_logLoss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "examine_Cs(trainset, y_train_df['is_positive_sentiment'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "def plot_accuracy_and_logLoss(range, train_acc, test_acc, train_logLoss, test_logLoss):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "    ax[0].plot(range, train_acc, color=\"red\", label=\"train\")\n",
    "    ax[0].plot(range, test_acc, color=\"blue\", label=\"test\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('Max iterations')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[1].plot(range, train_logLoss, color=\"red\", label=\"train\")\n",
    "    ax[1].plot(range, test_logLoss, color=\"blue\", label=\"test\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('Max_iterations')\n",
    "    ax[1].set_ylabel('Log loss')\n",
    "    plt.show()\n",
    "\n",
    "def examine_max_iters(data_train, label_train):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_logLoss = []\n",
    "    test_logLoss = []\n",
    "    for m in [10, 50, 100, 150, 200, 250, 300, 350]:\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "        train_acc_fold = []\n",
    "        test_acc_fold = []\n",
    "        train_logLoss_fold = []\n",
    "        test_logLoss_fold = []\n",
    "        for train_index, test_index in kf.split(data_train):\n",
    "            X_train, X_test = data_train.loc[train_index], data_train.loc[test_index]\n",
    "            y_train, y_test = label_train[train_index], label_train[test_index]\n",
    "            lr = LogisticRegression(C = 2.154434690031882, max_iter=m)\n",
    "            lr.fit(X_train, y_train)\n",
    "\n",
    "            train_acc_fold.append(lr.score(X_train, y_train))\n",
    "            test_acc_fold.append(lr.score(X_test, y_test))\n",
    "            train_logLoss_fold.append(log_loss(y_train, lr.predict(X_train)))\n",
    "            test_logLoss_fold.append(log_loss(y_test, lr.predict(X_test)))\n",
    "        print(\"Max iteration: %d\" % m)\n",
    "        print(\"Training accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in train_acc_fold), \"Mean: \", '%0.3f'%np.mean(train_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_acc_fold))\n",
    "        print(\"Testing accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in test_acc_fold), \"Mean: \", '%0.3f'%np.mean(test_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_acc_fold))\n",
    "        print(\"Training log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in train_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(train_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_logLoss_fold))\n",
    "        print(\"Testing log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in test_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(test_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_logLoss_fold), \"\\n\")\n",
    "\n",
    "        # train_acc.append(sum(train_acc_fold)/4)\n",
    "        # test_acc.append(sum(test_acc_fold)/4)\n",
    "        # train_logLoss.append(sum(train_logLoss_fold)/4)\n",
    "        # test_logLoss.append(sum(test_logLoss_fold)/4)\n",
    "    # plot_accuracy_and_logLoss([10, 50, 100, 150, 200, 250, 300, 350], train_acc, test_acc, train_logLoss, test_logLoss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "examine_max_iters(trainset, y_train_df['is_positive_sentiment'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "test_set = pd.read_csv('test_data.csv')\n",
    "prediction = grid_search.predict_proba(test_set)[:,1]\n",
    "np.savetxt('yproba1_test.txt', prediction)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM TFIDF Unigram with stopwords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "base_svm = SVC()\n",
    "base_svm.fit(x_train2, y_train2)\n",
    "print(base_svm.score(x_train2, y_train2))\n",
    "print(base_svm.score(x_test2, y_test2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9925373134328358\n",
      "0.7929292929292929\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# base_svm = SVC()\n",
    "# base_svm.fit(x_train, y_train)\n",
    "# print(base_svm.score(x_train, y_train))\n",
    "# print(base_svm.score(x_test, y_test))\n",
    "# 0.9912935323383084\n",
    "# 0.7941919191919192"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "tune_svc = SVC(random_state = 0, probability=True)\n",
    "svc_search = RandomizedSearchCV(tune_svc, param_distributions = svc_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1, n_iter=50)\n",
    "svc_search.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(probability=True, random_state=0),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.0001, 0.001, 0.01],\n",
       "                                        'degree': [1, 2, 3, 4, 5],\n",
       "                                        'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                                        'kernel': ['linear', 'rbf', 'poly']},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "print('Best parameters found:\\n', svc_search.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % svc_search.score(x_train, y_train))\n",
    "print(\" Test accuracy: %.4f\" % svc_search.score(x_test, y_test))\n",
    "# Best parameters found:\n",
    "#  {'kernel': 'poly', 'gamma': 100, 'degree': 2, 'C': 0.001}\n",
    "# Train accuracy: 0.9988\n",
    "#  Test accuracy: 0.7879"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'kernel': 'poly', 'gamma': 100, 'degree': 1, 'C': 0.01}\n",
      "Train accuracy: 0.9496\n",
      " Test accuracy: 0.7929\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "def plot_accuracy_and_logLoss(range, train_acc, test_acc, train_logLoss, test_logLoss):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "    ax[0].plot(range, train_acc, color=\"red\", label=\"train\")\n",
    "    ax[0].plot(range, test_acc, color=\"blue\", label=\"test\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('C values')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[1].plot(range, train_logLoss, color=\"red\", label=\"train\")\n",
    "    ax[1].plot(range, test_logLoss, color=\"blue\", label=\"test\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('C values')\n",
    "    ax[1].set_ylabel('Log loss')\n",
    "    plt.show()\n",
    "\n",
    "def examine_Cs(data_train, label_train):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_logLoss = []\n",
    "    test_logLoss = []\n",
    "    for c in np.logspace(-3, -1, 10):\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "        train_acc_fold = []\n",
    "        test_acc_fold = []\n",
    "        train_logLoss_fold = []\n",
    "        test_logLoss_fold = []\n",
    "        for train_index, test_index in kf.split(data_train):\n",
    "            X_train, X_test = data_train.loc[train_index], data_train.loc[test_index]\n",
    "            y_train, y_test = label_train[train_index], label_train[test_index]\n",
    "            svc = SVC(kernel='poly', gamma=100, degree=1, C = c)\n",
    "            svc.fit(X_train, y_train)\n",
    "\n",
    "            train_acc_fold.append(svc.score(X_train, y_train))\n",
    "            test_acc_fold.append(svc.score(X_test, y_test))\n",
    "            train_logLoss_fold.append(log_loss(y_train, svc.predict(X_train)))\n",
    "            test_logLoss_fold.append(log_loss(y_test, svc.predict(X_test)))\n",
    "        print(\"C value: %0.4f\" % c)\n",
    "        print(\"Training accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in train_acc_fold), \"Mean: \", '%0.3f'%np.mean(train_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_acc_fold))\n",
    "        print(\"Testing accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in test_acc_fold), \"Mean: \", '%0.3f'%np.mean(test_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_acc_fold))\n",
    "        print(\"Training log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in train_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(train_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_logLoss_fold))\n",
    "        print(\"Testing log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in test_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(test_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_logLoss_fold), \"\\n\")\n",
    "        \n",
    "        train_acc.append(sum(train_acc_fold)/4)\n",
    "        test_acc.append(sum(test_acc_fold)/4)\n",
    "        train_logLoss.append(sum(train_logLoss_fold)/4)\n",
    "        test_logLoss.append(sum(test_logLoss_fold)/4)\n",
    "    plot_accuracy_and_logLoss(np.logspace(-3, -1, 10), train_acc, test_acc, train_logLoss, test_logLoss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "examine_Cs(trainset, y_train_df['is_positive_sentiment'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C value: 0.0010\n",
      "Training accuracy scores for 4 folds are:  0.857 0.880 0.828 0.819 Mean:  0.846 Std:  0.024\n",
      "Testing accuracy scores for 4 folds are:  0.778 0.810 0.763 0.698 Mean:  0.762 Std:  0.041\n",
      "Training log loss for 4 folds are:  4.931 4.145 5.948 6.255 Mean:  5.320 Std:  0.837\n",
      "Testing log loss for 4 folds are:  7.656 6.562 8.174 10.419 Mean:  8.203 Std:  1.406 \n",
      "\n",
      "C value: 0.0017\n",
      "Training accuracy scores for 4 folds are:  0.895 0.896 0.887 0.884 Mean:  0.890 Std:  0.005\n",
      "Testing accuracy scores for 4 folds are:  0.800 0.818 0.822 0.758 Mean:  0.800 Std:  0.025\n",
      "Training log loss for 4 folds are:  3.627 3.588 3.914 4.010 Mean:  3.785 Std:  0.181\n",
      "Testing log loss for 4 folds are:  6.908 6.275 6.159 8.347 Mean:  6.922 Std:  0.871 \n",
      "\n",
      "C value: 0.0028\n",
      "Training accuracy scores for 4 folds are:  0.911 0.909 0.904 0.903 Mean:  0.907 Std:  0.003\n",
      "Testing accuracy scores for 4 folds are:  0.813 0.827 0.828 0.785 Mean:  0.813 Std:  0.017\n",
      "Training log loss for 4 folds are:  3.070 3.128 3.300 3.358 Mean:  3.214 Std:  0.119\n",
      "Testing log loss for 4 folds are:  6.447 5.987 5.929 7.426 Mean:  6.447 Std:  0.600 \n",
      "\n",
      "C value: 0.0046\n",
      "Training accuracy scores for 4 folds are:  0.926 0.926 0.926 0.920 Mean:  0.924 Std:  0.002\n",
      "Testing accuracy scores for 4 folds are:  0.802 0.828 0.815 0.788 Mean:  0.808 Std:  0.015\n",
      "Training log loss for 4 folds are:  2.571 2.571 2.571 2.763 Mean:  2.619 Std:  0.083\n",
      "Testing log loss for 4 folds are:  6.850 5.929 6.390 7.311 Mean:  6.620 Std:  0.515 \n",
      "\n",
      "C value: 0.0077\n",
      "Training accuracy scores for 4 folds are:  0.938 0.937 0.939 0.934 Mean:  0.937 Std:  0.002\n",
      "Testing accuracy scores for 4 folds are:  0.798 0.828 0.820 0.787 Mean:  0.808 Std:  0.017\n",
      "Training log loss for 4 folds are:  2.130 2.168 2.111 2.283 Mean:  2.173 Std:  0.067\n",
      "Testing log loss for 4 folds are:  6.965 5.929 6.217 7.368 Mean:  6.620 Std:  0.574 \n",
      "\n",
      "C value: 0.0129\n",
      "Training accuracy scores for 4 folds are:  0.955 0.946 0.951 0.949 Mean:  0.950 Std:  0.003\n",
      "Testing accuracy scores for 4 folds are:  0.803 0.828 0.810 0.783 Mean:  0.806 Std:  0.016\n",
      "Training log loss for 4 folds are:  1.554 1.861 1.708 1.746 Mean:  1.717 Std:  0.110\n",
      "Testing log loss for 4 folds are:  6.793 5.929 6.562 7.483 Mean:  6.692 Std:  0.556 \n",
      "\n",
      "C value: 0.0215\n",
      "Training accuracy scores for 4 folds are:  0.962 0.962 0.959 0.964 Mean:  0.962 Std:  0.002\n",
      "Testing accuracy scores for 4 folds are:  0.797 0.813 0.798 0.783 Mean:  0.798 Std:  0.011\n",
      "Training log loss for 4 folds are:  1.305 1.324 1.420 1.247 Mean:  1.324 Std:  0.062\n",
      "Testing log loss for 4 folds are:  7.023 6.447 6.965 7.483 Mean:  6.980 Std:  0.367 \n",
      "\n",
      "C value: 0.0359\n",
      "Training accuracy scores for 4 folds are:  0.972 0.972 0.972 0.973 Mean:  0.972 Std:  0.001\n",
      "Testing accuracy scores for 4 folds are:  0.778 0.807 0.795 0.772 Mean:  0.788 Std:  0.014\n",
      "Training log loss for 4 folds are:  0.959 0.979 0.959 0.921 Mean:  0.955 Std:  0.021\n",
      "Testing log loss for 4 folds are:  7.656 6.678 7.081 7.886 Mean:  7.325 Std:  0.475 \n",
      "\n",
      "C value: 0.0599\n",
      "Training accuracy scores for 4 folds are:  0.979 0.979 0.979 0.980 Mean:  0.980 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.780 0.792 0.788 0.752 Mean:  0.778 Std:  0.016\n",
      "Training log loss for 4 folds are:  0.710 0.710 0.710 0.691 Mean:  0.705 Std:  0.008\n",
      "Testing log loss for 4 folds are:  7.599 7.196 7.311 8.577 Mean:  7.671 Std:  0.544 \n",
      "\n",
      "C value: 0.1000\n",
      "Training accuracy scores for 4 folds are:  0.987 0.987 0.986 0.987 Mean:  0.987 Std:  0.001\n",
      "Testing accuracy scores for 4 folds are:  0.765 0.785 0.780 0.727 Mean:  0.764 Std:  0.023\n",
      "Training log loss for 4 folds are:  0.461 0.441 0.499 0.461 Mean:  0.465 Std:  0.021\n",
      "Testing log loss for 4 folds are:  8.117 7.426 7.599 9.441 Mean:  8.145 Std:  0.790 \n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. Next"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "C = [.0001, .001, .01]\n",
    "gamma = [.001, .01, .1, 1, 10, 100]\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "\n",
    "svc_grid = {'C':C,\n",
    "    'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'degree': degree\n",
    "             }\n",
    "\n",
    "tune_svc = SVC(random_state = 0, probability=True)\n",
    "svc_search = RandomizedSearchCV(tune_svc, param_distributions = svc_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1, n_iter=50)\n",
    "svc_search.fit(x_train2, y_train2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(probability=True, random_state=0),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.0001, 0.001, 0.01],\n",
       "                                        'degree': [1, 2, 3, 4, 5],\n",
       "                                        'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                                        'kernel': ['linear', 'rbf', 'poly']},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "print('Best parameters found:\\n', svc_search.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % svc_search.score(x_train2, y_train2))\n",
    "print(\" Test accuracy: %.4f\" % svc_search.score(x_test2, y_test2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'kernel': 'poly', 'gamma': 100, 'degree': 2, 'C': 0.001}\n",
      "Train accuracy: 0.9994\n",
      " Test accuracy: 0.8030\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "svcf = SVC(kernel='poly', gamma=100, degree=2, C=0.001)\n",
    "svcf.fit(x_train2, y_train2)\n",
    "print(svcf.score(x_train2, y_train2))\n",
    "print(svcf.score(x_test2, y_test2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9993781094527363\n",
      "0.803030303030303\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "def plot_accuracy_and_logLoss(range, train_acc, test_acc, train_logLoss, test_logLoss):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "    ax[0].plot(range, train_acc, color=\"red\", label=\"train\")\n",
    "    ax[0].plot(range, test_acc, color=\"blue\", label=\"test\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('Coef0 values')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[1].plot(range, train_logLoss, color=\"red\", label=\"train\")\n",
    "    ax[1].plot(range, test_logLoss, color=\"blue\", label=\"test\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('Coef0 values')\n",
    "    ax[1].set_ylabel('Log loss')\n",
    "    plt.show()\n",
    "\n",
    "def examine_Cs(data_train, label_train):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_logLoss = []\n",
    "    test_logLoss = []\n",
    "    for c in np.logspace(-1, 1.5, 10):\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "        train_acc_fold = []\n",
    "        test_acc_fold = []\n",
    "        train_logLoss_fold = []\n",
    "        test_logLoss_fold = []\n",
    "        for train_index, test_index in kf.split(data_train):\n",
    "            X_train, X_test = data_train.loc[train_index], data_train.loc[test_index]\n",
    "            y_train, y_test = label_train[train_index], label_train[test_index]\n",
    "            svc = SVC(kernel='poly', gamma=100, degree=2, C = 0.00068129, coef0 = c)\n",
    "            svc.fit(X_train, y_train)\n",
    "\n",
    "            train_acc_fold.append(svc.score(X_train, y_train))\n",
    "            test_acc_fold.append(svc.score(X_test, y_test))\n",
    "            train_logLoss_fold.append(log_loss(y_train, svc.predict(X_train)))\n",
    "            test_logLoss_fold.append(log_loss(y_test, svc.predict(X_test)))\n",
    "        print(\"Coef0 value: %0.4f\" % c)\n",
    "        print(\"Training accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in train_acc_fold), \"Mean: \", '%0.3f'%np.mean(train_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_acc_fold))\n",
    "        print(\"Testing accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in test_acc_fold), \"Mean: \", '%0.3f'%np.mean(test_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_acc_fold))\n",
    "        print(\"Training log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in train_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(train_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_logLoss_fold))\n",
    "        print(\"Testing log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in test_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(test_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_logLoss_fold), \"\\n\")\n",
    "        \n",
    "        train_acc.append(sum(train_acc_fold)/4)\n",
    "        test_acc.append(sum(test_acc_fold)/4)\n",
    "        train_logLoss.append(sum(train_logLoss_fold)/4)\n",
    "        test_logLoss.append(sum(test_logLoss_fold)/4)\n",
    "    plot_accuracy_and_logLoss(np.logspace(-1, 1.5, 10), train_acc, test_acc, train_logLoss, test_logLoss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "np.logspace(-4,-1.5,10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.0001    , 0.00018957, 0.00035938, 0.00068129, 0.00129155,\n",
       "       0.00244844, 0.00464159, 0.00879923, 0.01668101, 0.03162278])"
      ]
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "examine_Cs(trainset2, y_train_df['is_positive_sentiment'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coef0 value: 0.1000\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.805 0.827 0.845 0.823 Mean:  0.825 Std:  0.014\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.735 5.987 5.354 6.102 Mean:  6.044 Std:  0.490 \n",
      "\n",
      "Coef0 value: 0.1896\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.805 0.827 0.845 0.823 Mean:  0.825 Std:  0.014\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.735 5.987 5.354 6.102 Mean:  6.044 Std:  0.490 \n",
      "\n",
      "Coef0 value: 0.3594\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.807 0.828 0.845 0.823 Mean:  0.826 Std:  0.014\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.678 5.929 5.354 6.102 Mean:  6.016 Std:  0.472 \n",
      "\n",
      "Coef0 value: 0.6813\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.805 0.828 0.847 0.823 Mean:  0.826 Std:  0.015\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.735 5.929 5.296 6.102 Mean:  6.016 Std:  0.512 \n",
      "\n",
      "Coef0 value: 1.2915\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.805 0.830 0.848 0.823 Mean:  0.827 Std:  0.016\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.735 5.872 5.238 6.102 Mean:  5.987 Std:  0.535 \n",
      "\n",
      "Coef0 value: 2.4484\n",
      "Training accuracy scores for 4 folds are:  0.999 0.999 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.805 0.828 0.848 0.825 Mean:  0.827 Std:  0.015\n",
      "Training log loss for 4 folds are:  0.019 0.038 0.038 0.019 Mean:  0.029 Std:  0.010\n",
      "Testing log loss for 4 folds are:  6.735 5.929 5.238 6.044 Mean:  5.987 Std:  0.531 \n",
      "\n",
      "Coef0 value: 4.6416\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.802 0.830 0.855 0.822 Mean:  0.827 Std:  0.019\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.850 5.872 5.008 6.159 Mean:  5.972 Std:  0.661 \n",
      "\n",
      "Coef0 value: 8.7992\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.802 0.832 0.848 0.827 Mean:  0.827 Std:  0.017\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.850 5.814 5.238 5.987 Mean:  5.972 Std:  0.578 \n",
      "\n",
      "Coef0 value: 16.6810\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.800 0.825 0.842 0.825 Mean:  0.823 Std:  0.015\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.908 6.044 5.469 6.044 Mean:  6.116 Std:  0.514 \n",
      "\n",
      "Coef0 value: 31.6228\n",
      "Training accuracy scores for 4 folds are:  0.999 1.000 0.999 0.999 Mean:  0.999 Std:  0.000\n",
      "Testing accuracy scores for 4 folds are:  0.800 0.820 0.827 0.817 Mean:  0.816 Std:  0.010\n",
      "Training log loss for 4 folds are:  0.019 0.000 0.038 0.019 Mean:  0.019 Std:  0.014\n",
      "Testing log loss for 4 folds are:  6.908 6.217 5.987 6.332 Mean:  6.361 Std:  0.339 \n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "svcc = SVC(kernel='poly', gamma=100, degree=2, C = 0.00068129, coef0 = 2.4484, probability=True)\n",
    "svcc.fit(x_train2, y_train2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVC(C=0.00068129, coef0=2.4484, degree=2, gamma=100, kernel='poly',\n",
       "    probability=True)"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "test_set = pd.read_csv('test_data.csv')\n",
    "prediction = svcc.predict_proba(test_set)[:,1]\n",
    "np.savetxt('yproba1_test.txt', prediction)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MLP TFIDF Unigram without stopwords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "len(x_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "network = MLPClassifier(max_iter=400, random_state=0, early_stopping=True)\n",
    "network.fit(x_train, y_train)\n",
    "print(\"Train accuracy: %.4f\" % network.score(x_train, y_train))\n",
    "print(\" Test accuracy: %.4f\" % network.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy: 0.9210\n",
      " Test accuracy: 0.7727\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "try_params = {\n",
    "    'activation': ['logistic', 'relu', 'identity', 'tanh'],\n",
    "    'hidden_layer_sizes': [(50,), (100,), (128, 64, 32, 8)],\n",
    "    'alpha': np.logspace(-2, 2, 10),\n",
    "    'learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "    'solver': ['lbfgs', 'adam', 'sgd']\n",
    "}\n",
    "network = MLPClassifier(max_iter=400, random_state=0, early_stopping=True)\n",
    "gscv = RandomizedSearchCV(network, param_distributions = try_params, cv=3, n_jobs=-1, n_iter=50)\n",
    "gscv.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=MLPClassifier(early_stopping=True, max_iter=400,\n",
       "                                           random_state=0),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'activation': ['logistic', 'relu',\n",
       "                                                       'identity', 'tanh'],\n",
       "                                        'alpha': array([1.00000000e-02, 2.78255940e-02, 7.74263683e-02, 2.15443469e-01,\n",
       "       5.99484250e-01, 1.66810054e+00, 4.64158883e+00, 1.29154967e+01,\n",
       "       3.59381366e+01, 1.00000000e+02]),\n",
       "                                        'hidden_layer_sizes': [(50,), (100,),\n",
       "                                                               (128, 64, 32,\n",
       "                                                                8)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'solver': ['lbfgs', 'adam', 'sgd']})"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "print('Best parameters found:\\n', gscv.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % gscv.score(x_train, y_train))\n",
    "print(\" Test accuracy: %.4f\" % gscv.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'solver': 'lbfgs', 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 12.915496650148826, 'activation': 'relu'}\n",
      "Train accuracy: 0.9515\n",
      " Test accuracy: 0.8030\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "best_mlp = gscv.best_estimator_\n",
    "best_mlp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=12.915496650148826, early_stopping=True, max_iter=400,\n",
       "              random_state=0, solver='lbfgs')"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "\n",
    "def plot_accuracy_and_logLoss(range, train_acc, test_acc, train_logLoss, test_logLoss):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 6))\n",
    "    ax[0].plot(range, train_acc, color=\"red\", label=\"train\")\n",
    "    ax[0].plot(range, test_acc, color=\"blue\", label=\"test\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('Tolerance values')\n",
    "    ax[0].set_ylabel('Accuracy')\n",
    "    ax[1].plot(range, train_logLoss, color=\"red\", label=\"train\")\n",
    "    ax[1].plot(range, test_logLoss, color=\"blue\", label=\"test\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('Tolerance values')\n",
    "    ax[1].set_ylabel('Log loss')\n",
    "    plt.show()\n",
    "\n",
    "def examine_tols(data_train, label_train):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_logLoss = []\n",
    "    test_logLoss = []\n",
    "    for t in np.logspace(-3,-1,10):\n",
    "        kf = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "        train_acc_fold = []\n",
    "        test_acc_fold = []\n",
    "        train_logLoss_fold = []\n",
    "        test_logLoss_fold = []\n",
    "        for train_index, test_index in kf.split(data_train):\n",
    "            X_train, X_test = data_train.loc[train_index], data_train.loc[test_index]\n",
    "            y_train, y_test = label_train[train_index], label_train[test_index]\n",
    "            mlp = MLPClassifier(max_iter=400, random_state=0, early_stopping=True, solver='lbfgs', learning_rate= 'constant', hidden_layer_sizes=(100,), activation='relu', \n",
    "            alpha=14.67799268, tol = t)\n",
    "            mlp.fit(X_train, y_train)\n",
    "\n",
    "            train_acc_fold.append(mlp.score(X_train, y_train))\n",
    "            test_acc_fold.append(mlp.score(X_test, y_test))\n",
    "            train_logLoss_fold.append(log_loss(y_train, mlp.predict(X_train)))\n",
    "            test_logLoss_fold.append(log_loss(y_test, mlp.predict(X_test)))\n",
    "        print(\"Tolerance value: %0.4f\" % t)\n",
    "        print(\"Training accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in train_acc_fold), \"Mean: \", '%0.3f'%np.mean(train_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_acc_fold))\n",
    "        print(\"Testing accuracy scores for 4 folds are: \", \" \".join('%0.3f'%x for x in test_acc_fold), \"Mean: \", '%0.3f'%np.mean(test_acc_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_acc_fold))\n",
    "        print(\"Training log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in train_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(train_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(train_logLoss_fold))\n",
    "        print(\"Testing log loss for 4 folds are: \", \" \".join('%0.3f'%x for x in test_logLoss_fold), \"Mean: \", '%0.3f'%np.mean(test_logLoss_fold), \n",
    "        \"Std: \", '%0.3f'%np.std(test_logLoss_fold), \"\\n\")\n",
    "        \n",
    "        train_acc.append(sum(train_acc_fold)/4)\n",
    "        test_acc.append(sum(test_acc_fold)/4)\n",
    "        train_logLoss.append(sum(train_logLoss_fold)/4)\n",
    "        test_logLoss.append(sum(test_logLoss_fold)/4)\n",
    "    plot_accuracy_and_logLoss(np.logspace(-3,-1,10), train_acc, test_acc, train_logLoss, test_logLoss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "examine_tols(trainset, y_train_df['is_positive_sentiment'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "mlp = MLPClassifier(max_iter=400, random_state=0, early_stopping=True, solver='lbfgs', learning_rate= 'constant', hidden_layer_sizes=(100,), activation='relu', \n",
    "            alpha=14.67799268, tol = 1e-3)\n",
    "mlp.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=14.67799268, early_stopping=True, max_iter=400,\n",
       "              random_state=0, solver='lbfgs', tol=0.001)"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "test_pred = mlp.predict(x_test)\n",
    "idx = x_test[test_pred != y_test].index\n",
    "wrong = x_train_df.loc[idx,]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "for i, text in enumerate(wrong['text']):\n",
    "    print(text)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not to mention the combination of pears, almonds and bacon is a big winner!\n",
      "Perfect for someone (me) who only likes beer ice cold, or in this case, even colder.\n",
      "Steer clear of this product and go with the genuine Palm replacementr pens, which come in a three-pack.\n",
      "Small, sleek, impressive looking, practical setup with ample storage in place.\n",
      "This place should honestly be blown up.\n",
      "Magical Help.\n",
      "The descriptions said \"yum yum sauce\" and another said \"eel sauce\", yet another said \"spicy mayo\"...well NONE of the rolls had sauces on them.\n",
      "Someone shouldve invented this sooner.\n",
      "The color is even prettier than I thought it would be, and the graphics are incredibly sharp.\n",
      "We'd definitely go back here again.\n",
      "I really wanted the Plantronics 510 to be the right one, but it has too many issues for me.The good\n",
      "If it was to turn my good day feeling into a night of disturbing memories than I guess he succeeded.  \n",
      "The only place good for this film is in the garbage.  \n",
      "Unless you're just out to visually \"collect\" all extant films of Austen's work, you can skip this one.  \n",
      "I did not have any problem with this item and would order it again if needed.\n",
      "It was a pale color instead of nice and char and has NO flavor.\n",
      "The place was fairly clean but the food simply wasn't worth it.\n",
      "I tried talking real loud but shouting on the telephone gets old and I was still told it wasn't great.\n",
      "Plantronics Bluetooth Excelent Buy.\n",
      "The service here is fair at best.\n",
      "Unfortunately, we must have hit the bakery on leftover day because everything we ordered was STALE.\n",
      "It's as continuously beautiful to look at as a Bertolucci, but the relationships here are more convincing and the narrative more engaging than some of that master's work.  \n",
      "I have watched their prices inflate, portions get smaller and management attitudes grow rapidly!\n",
      "The lighting is just dark enough to set the mood.\n",
      "The phone loads super!\n",
      "I bought these hoping I could make my Bluetooth headset fit better but these things made it impossible to wear.\n",
      "My phone sounded OK ( not great - OK), but my wife's phone was almost totally unintelligible, she couldn't understand a word being said on it.\n",
      "The service was poor and thats being nice.\n",
      "Go rent it.  \n",
      "I asked multiple times for the wine list and after some time of being ignored I went to the hostess and got one myself.\n",
      "Crostini that came with the salad was stale.\n",
      "The fish is badly made and some of its underwater shots are repeated a thousand times in the film.  \n",
      "It has been a winner for us.\n",
      "It was a very superficial movie and it gave me the feeling that I was watching play rather than a film.  \n",
      "The atmosphere is modern and hip, while maintaining a touch of coziness.\n",
      "I was able to do voice dialing in the car with no problem.\n",
      ":) Anyway, the plot flowed smoothly and the male-bonding scenes were a hoot.  \n",
      "It is super charged up for use as a small hybrid palmtop/camera/cellphone, and excels in those roles.\n",
      "Then a few days later the a puff of smoke came out of the phone while in use.\n",
      "There were too many close ups.  \n",
      "No complaints!\n",
      "PS the only scene in the movie that was cool is when the central character finds her room blown up.  \n",
      "If someone orders two tacos don't' you think it may be part of customer service to ask if it is combo or ala cart?\n",
      "This movie is also revealing.  \n",
      "In particular the relationship between the bakery assistant and the waitress just didn't work for me at all.  \n",
      "You won't forget this movie!  \n",
      "Now this dish was quite flavourful.\n",
      "Regardless, the film fails on most levels.  \n",
      "Works for me.\n",
      "I really hope the team behind this movie makes more movies, and that they will continue to do so in their own, some kinda weird style.  \n",
      "The ambiance isn't much better.\n",
      "Only had this a month but it's worked flawlessly so far.\n",
      "If you have not seen this movie, I definitely recommend it!  \n",
      "The black eyed peas and sweet potatoes... UNREAL!\n",
      "If you check the director's filmography on this site you will see why this film didn't have a chance.  \n",
      "Virgin Wireless rocks and so does this cheap little phone!\n",
      "Much less than the jawbone I was going to replace it with.\n",
      "Appears to actually outperform the original battery from China that came with my V325i.\n",
      "10/10  \n",
      "Also its slim enough to fit into my alarm clock docking station without removing the case.\n",
      "* Both the Hot & Sour & the Egg Flower Soups were absolutely 5 Stars!\n",
      "It's kind of embarrassing to use because of how it looks and mostly it's embarrassing how child-like the company is.\n",
      "After a year the battery went completely dead on my headset.\n",
      "If you act in such a film, you should be glad that you're gonna drift away from earth as far as possible!  \n",
      "It will drive you barking mad!  \n",
      "much better than the hard plastic cases.\n",
      "This is definitely a must have if your state does not allow cell phone usage while driving.\n",
      "It is so small and you don't even realize that it is there after a while of getting used to it.\n",
      "It was that loud.Glad to say that the Plantronics 510 maintains a flawless connection to my cell and with no static during normal use.\n",
      "I've had better bagels from the grocery store.\n",
      "The building itself seems pretty neat; the bathroom is pretty trippy, but I wouldn't eat here again.\n",
      "Still, I do like this movie for it's empowerment of women; there's not enough movies out there like this one.  \n",
      "The Buffet at Bellagio was far from what I anticipated.\n",
      "Battery charge-life is quite long.\n",
      "In addition to having one of the most lovely songs ever written, French Cancan also boasts one of the cutest leading ladies ever to grace the screen.  \n",
      "It crackles with an unpredictable, youthful energy - but honestly, i found it hard to follow and concentrate on it meanders so badly.  \n",
      "GO AND SEE IT!  \n",
      "Anne Heche was utterly convincing.  \n",
      "Must have been an off night at this place.\n",
      "I like design and look of Jabra behing the ear headsets and 5020 is pretty comfortible to wear 24 hours a day without pain in the ear.\n",
      "10 out of 10 stars.  \n",
      "I don't think it would hold it too securly on your belt.\n",
      "We made the drive all the way from North Scottsdale... and I was not one bit disappointed!\n",
      "It is not just a cult... it is a cult CLASSIC.  \n",
      "I own 2 of these cases and would order another.\n",
      "My father has the V265, and the battery is dying.\n",
      "Any grandmother can make a roasted chicken better than this one.\n",
      "Mic Doesn't work.\n",
      "OMG I felt like I had never eaten Thai food until this dish.\n",
      "The stories were as unbelievable as the actors.  \n",
      "He's a national treasure.  \n",
      "- They never brought a salad we asked for.\n",
      "Now the burgers aren't as good, the pizza which used to be amazing is doughy and flavorless.\n",
      "I got it because it was so small and adorable.\n",
      "For that price I can think of a few place I would have much rather gone.\n",
      "The nano stated it.My son was dissapointed.\n",
      "You cant go wrong with any of the food here.\n",
      "But this understated film leaves a lasting impression.  \n",
      "Tasted like dirt.\n",
      "The film's sole bright spot was Jonah Hill (who will look almost unrecognizable to fans of the recent Superbad due to the amount of weight he lost in the interim).  \n",
      "We've tried to like this place but after 10+ times I think we're done with them.\n",
      "This film highlights the fundamental flaws of the legal process, that it's not about discovering guilt or innocence, but rather, is about who presents better in court.  \n",
      "That was done in the second movie.  \n",
      "Be sure to order dessert, even if you need to pack it to-go - the tiramisu and cannoli are both to die for.\n",
      "The soundtrack wasn't terrible, either.  \n",
      "Food was so gooodd.\n",
      "Her lines seem to have been WRITTEN by a fifteen year old, though they are trying oh so, so hard to sound like how a fifteen year old would really, um, you know, well... talk.  \n",
      "As a courtroom drama, it's compelling, as an indictment on the American justice system, it's frightening.  \n",
      "On three different occasions I asked for well done or medium well, and all three times I got the bloodiest piece of meat on my plate.\n",
      "* Comes with a strong light that you can use to light up your camera shots, and even flash SOS signals (seriously!\n",
      "Plus, it's only 8 bucks.\n",
      "If you have several dozen or several hundred contacts, then imagine the fun of sending each of them one by one.\n",
      "The last 15 minutes of movie are also not bad as well.  \n",
      "The plastic breaks really easy on this clip.\n",
      "Shot in the Southern California desert using his patent faux documentary style, Watkins creates a film like no other.  \n",
      "Artless camera-work endlessly presents us with the ugliest setting imaginable, i.e.  \n",
      "I give it 2 thumbs down\n",
      "The characters were all funny and had the peculiarity of not having a true lead character.  \n",
      "And, FINALLY, after all that, we get to an ending that would've been great had it been handled by competent people and not Jerry Falwell.  \n",
      "Not much dialogue, not much music, the whole film was shot as elaborately and aesthetically like a sculpture.  \n",
      "I can think of no other film where something vitally important occurs every other minute.  \n",
      "There's barely a boring moment in the film and there are plenty of humorous parts.  \n",
      "Arrived quickly and much less expensive than others being sold.\n",
      "It doesn't make you look cool.\n",
      "All in all, I'd expected a better consumer experience from Motorola.\n",
      "But, in any case, the best part is, you can download these pictures to your laptop using IR, or even send pictures from your laptop to the phone.\n",
      "You won't be disappointed.\n",
      "It was pretty gross!\n",
      "The movie is not completely perfect but 'Titta Di Girolamo' will stay with you for a long time after the vision of the movie.  \n",
      "We would recommend these to others.\n",
      "There is really nothing for me at postinos, hope your experience is better\n",
      "The waiter wasn't helpful or friendly and rarely checked on us.\n",
      "It was an inexpensive piece, but I would still have expected better quality.\n",
      "All in all, I can assure you I'll be back.\n",
      "You get extra minutes so that you can carry out the call and not get cut off.\"\n",
      "My 5-year old Nokia 2160 from Tracfone holds the charge a lot better than this.\n",
      "I did not expect this to be so good!\n",
      "like the other reviewer said \"you couldn't pay me to eat at this place again.\"\n",
      "This one just fails to create any real suspense.  \n",
      "I will never forget it now.  \n",
      "But this movie really got to me.  \n",
      "good protection and does not make phone too bulky.\n",
      "The range is very decent, I've been able to roam around my house with the phone in the living room with no reception/sound quality issues.\n",
      "I can assure you that you won't be disappointed.\n",
      "Full of unconvincing cardboard characters it is blandly written by Edward Chodorov, who also produced, and is surprisingly directed by Jean Negulesco from whom one would expect a great deal more.  \n",
      "I go to far too many places and I've never seen any restaurant that serves a 1 egg breakfast, especially for $4.00.\n",
      "Totally different, with loads of understatement and black comedy, this is a film few get to see, but those who do will remember it.  \n",
      "I cannot believe that the actors agreed to do this \"film\".  \n",
      "I've had this bluetoooth headset for some time now and still not comfortable with the way it fits on the ear.\n",
      "If you want a sandwich just go to any Firehouse!!!!!\n",
      "The acting by the whole cast could be put on a scale and balanced perfectly between overacting and underacting.  \n",
      "It's hard not to fall head-over-heels in love with that girl.  \n",
      "I'll definitely be in soon again.\n",
      "This was my first and only Vegas buffet and it did not disappoint.\n",
      "Its a total package.\n",
      "REALLY UGLY.\n",
      "Portable and it works.\n",
      "Unfortunately the ability to actually know you are receiving a call is a rather important feature and this phone is pitiful in that respect.\n",
      "Because both ears are occupied, background is not distracting at all.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "test_set = pd.read_csv('test_data.csv')\n",
    "prediction = mlp.predict_proba(test_set)[:,1]\n",
    "np.savetxt('yproba1_test.txt', prediction)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "np.logspace(1,1.5,10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([10.        , 11.36463666, 12.91549665, 14.67799268, 16.68100537,\n",
       "       18.95735652, 21.5443469 , 24.48436747, 27.82559402, 31.6227766 ])"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# network2 = MLPClassifier(max_iter=400, random_state=0, early_stopping=True)\n",
    "# network2.fit(x_train2, y_train2)\n",
    "# print(\"Train accuracy: %.4f\" % network2.score(x_train2, y_train2))\n",
    "# print(\" Test accuracy: %.4f\" % network2.score(x_test2, y_test2))\n",
    "# Train accuracy: 0.9248\n",
    "#  Test accuracy: 0.7955"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy: 0.9565\n",
      " Test accuracy: 0.7879\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# network2 = MLPClassifier(max_iter=400, random_state=0, early_stopping=True)\n",
    "# gscv2 = RandomizedSearchCV(network2, param_distributions = try_params, cv=3, n_jobs=-1, n_iter=50)\n",
    "# gscv2.fit(x_train2, y_train2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=MLPClassifier(early_stopping=True, max_iter=400,\n",
       "                                           random_state=0),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'activation': ['logistic', 'relu',\n",
       "                                                       'identity', 'tanh'],\n",
       "                                        'alpha': array([100. ,  10. ,   1. ,   0.1]),\n",
       "                                        'hidden_layer_sizes': [(50,), (100,),\n",
       "                                                               (128, 64, 32,\n",
       "                                                                8)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'solver': ['lbfgs', 'adam', 'sgd']})"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# print('Best parameters found:\\n', gscv2.best_params_)\n",
    "# print(\"Train accuracy: %.4f\" % gscv2.score(x_train2, y_train2))\n",
    "# print(\" Test accuracy: %.4f\" % gscv2.score(x_test2, y_test2))\n",
    "# Best parameters found:\n",
    "#  {'hidden_layer_sizes': (100,), 'alpha': 1.0, 'activation': 'relu'}\n",
    "# Train accuracy: 0.8843\n",
    "#  Test accuracy: 0.7702"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'solver': 'lbfgs', 'learning_rate': 'constant', 'hidden_layer_sizes': (50,), 'alpha': 10.0, 'activation': 'relu'}\n",
      "Train accuracy: 0.9608\n",
      " Test accuracy: 0.7955\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RF - not great"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "base_rfc = RandomForestClassifier(random_state = 0)\n",
    "base_rfc.fit(x_train, y_train)\n",
    "print(base_rfc.score(x_train, y_train))\n",
    "print(base_rfc.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9987562189054726\n",
      "0.773989898989899\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "min_samples_split = [2, 5, 10]\n",
    "max_depth = [int(x) for x in np.linspace(20, 100, num = 5)]\n",
    "max_depth.append(None)\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "rfc_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "tune_rfc = RandomForestClassifier(random_state = 0)\n",
    "rfc_search = RandomizedSearchCV(tune_rfc, param_distributions = rfc_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1)\n",
    "rfc_search.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=0),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [20, 40, 60, 80, 100,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "print('Best parameters found:\\n', rfc_search.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % rfc_search.score(x_train, y_train))\n",
    "print(\" Test accuracy: %.4f\" % rfc_search.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n",
      "Train accuracy: 0.9633\n",
      " Test accuracy: 0.7765\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "base_rfc = RandomForestClassifier(random_state = 0)\n",
    "base_rfc.fit(x_train2, y_train2)\n",
    "print(base_rfc.score(x_train2, y_train2))\n",
    "print(base_rfc.score(x_test2, y_test2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n",
      "0.7613636363636364\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient boostng - not great"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "base_gbc = GradientBoostingClassifier(random_state=8)\n",
    "base_gbc.fit(x_train, y_train)\n",
    "print(base_gbc.score(x_train, y_train))\n",
    "print(base_gbc.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8557213930348259\n",
      "0.7664141414141414\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "base_gbc = GradientBoostingClassifier(random_state=8)\n",
    "base_gbc.fit(x_train2, y_train2)\n",
    "print(base_gbc.score(x_train2, y_train2))\n",
    "print(base_gbc.score(x_test2, y_test2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8606965174129353\n",
      "0.7386363636363636\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "n_estimators = [200, 800]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [10, 40]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [10, 30, 50]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "learning_rate = [.1, .5]\n",
    "subsample = [.5, 1.]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'learning_rate': learning_rate,\n",
    "               'subsample': subsample}\n",
    "base_gbc = GradientBoostingClassifier(random_state=8)\n",
    "random_search = RandomizedSearchCV(estimator=base_gbc,param_distributions=random_grid, n_iter=50, scoring='accuracy', cv=3, verbose=1, n_jobs=-1, random_state=8)\n",
    "random_search.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=8),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.1, 0.5],\n",
       "                                        'max_depth': [10, 40, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [10, 30, 50],\n",
       "                                        'n_estimators': [200, 800],\n",
       "                                        'subsample': [0.5, 1.0]},\n",
       "                   random_state=8, scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "print('Best parameters found:\\n', random_search.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % random_search.score(x_train, y_train))\n",
    "print(\" Test accuracy: %.4f\" % random_search.score(x_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'subsample': 1.0, 'n_estimators': 800, 'min_samples_split': 50, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'learning_rate': 0.5}\n",
      "Train accuracy: 0.9988\n",
      " Test accuracy: 0.7891\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LR Bigrams without stopwords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df = 2)\n",
    "model = tfidf.fit_transform(df_clean['text'].values.tolist())\n",
    "features = tfidf.get_feature_names()\n",
    "dnse = model.todense()\n",
    "dnselist = dnse.tolist()\n",
    "\n",
    "features = tfidf.get_feature_names()\n",
    "df = pd.DataFrame(dnselist, columns=features)\n",
    "\n",
    "# with stopwords\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(df, y_train_df['is_positive_sentiment'], test_size=0.33, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "tfidf2 = TfidfVectorizer(ngram_range=(1,2), min_df = 2, stop_words=stop_words)\n",
    "model2 = tfidf2.fit_transform(df_clean['text'].values.tolist())\n",
    "features2 = tfidf2.get_feature_names()\n",
    "dnse2 = model2.todense()\n",
    "dnselist2 = dnse2.tolist()\n",
    "\n",
    "df2 = pd.DataFrame(dnselist2, columns=features2)\n",
    "\n",
    "# with stopwords\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(df2, y_train_df['is_positive_sentiment'], test_size=0.33, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# base_lr = LogisticRegression()\n",
    "# base_lr.fit(x_train3, y_train3)\n",
    "# print(base_lr.score(x_train3, y_train3))\n",
    "# print(base_lr.score(x_test3, y_test3))\n",
    "# 0.9651741293532339\n",
    "# 0.7765151515151515"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "base_lr = LogisticRegression()\n",
    "base_lr.fit(x_train4, y_train4)\n",
    "print(base_lr.score(x_train4, y_train4))\n",
    "print(base_lr.score(x_test4, y_test4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9527363184079602\n",
      "0.8042929292929293\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# param_grid = {\"C\":np.logspace(-3,3,10), \"max_iter\":[50, 150, 250, 350, 450, 500]}\n",
    "# tune_lr3 = LogisticRegression()\n",
    "# grid_search3 = RandomizedSearchCV(tune_lr3, param_distributions = param_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1, n_iter=50)\n",
    "# grid_search3.fit(x_train3, y_train3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# print('Best parameters found:\\n', grid_search3.best_params_)\n",
    "# print(\"Train accuracy: %.4f\" % grid_search3.score(x_train3, y_train3))\n",
    "# print(\" Test accuracy: %.4f\" % grid_search3.score(x_test3, y_test3))\n",
    "# Best parameters found:\n",
    "#  {'max_iter': 350, 'C': 10.0}\n",
    "# Train accuracy: 0.9969\n",
    "#  Test accuracy: 0.7980"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'max_iter': 350, 'C': 10.0}\n",
      "Train accuracy: 0.9969\n",
      " Test accuracy: 0.7980\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "tune_lr4 = LogisticRegression()\n",
    "grid_search4 = RandomizedSearchCV(tune_lr4, param_distributions = param_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1, n_iter=50)\n",
    "grid_search4.fit(x_train4, y_train4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=LogisticRegression(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03]),\n",
       "                                        'max_iter': [50, 150, 250, 350, 450,\n",
       "                                                     500]},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "print('Best parameters found:\\n', grid_search4.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % grid_search4.score(x_train4, y_train4))\n",
    "print(\" Test accuracy: %.4f\" % grid_search4.score(x_test4, y_test4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'max_iter': 500, 'C': 0.46415888336127775}\n",
      "Train accuracy: 0.9291\n",
      " Test accuracy: 0.8030\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "# df2.to_csv('important_words.csv', index=False)\n",
    "test_set = pd.read_csv('test_data.csv')\n",
    "prediction = grid_search4.predict_proba(test_set)[:,1]\n",
    "np.savetxt('yproba1_test.txt', prediction)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM Bigrams -- not as good"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "base_svm = SVC()\n",
    "base_svm.fit(x_train3, y_train3)\n",
    "print(base_svm.score(x_train3, y_train3))\n",
    "print(base_svm.score(x_test3, y_test3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9968905472636815\n",
      "0.7941919191919192\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "base_svm = SVC()\n",
    "base_svm.fit(x_train4, y_train4)\n",
    "print(base_svm.score(x_train4, y_train4))\n",
    "print(base_svm.score(x_test4, y_test4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9925373134328358\n",
      "0.8005050505050505\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "tune_svc3 = SVC(random_state = 0, probability=True)\n",
    "svc_search3 = RandomizedSearchCV(tune_svc3, param_distributions = svc_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1, n_iter=50)\n",
    "svc_search3.fit(x_train3, y_train3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(probability=True, random_state=0),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.0001, 0.001, 0.01],\n",
       "                                        'degree': [1, 2, 3, 4, 5],\n",
       "                                        'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                                        'kernel': ['linear', 'rbf', 'poly']},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "print('Best parameters found:\\n', svc_search3.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % svc_search3.score(x_train3, y_train3))\n",
    "print(\" Test accuracy: %.4f\" % svc_search3.score(x_test3, y_test3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'kernel': 'poly', 'gamma': 10, 'degree': 2, 'C': 0.01}\n",
      "Train accuracy: 0.9994\n",
      " Test accuracy: 0.7967\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "tune_svc4 = SVC(random_state = 0, probability=True)\n",
    "svc_search4 = RandomizedSearchCV(tune_svc4, param_distributions = svc_grid, scoring='accuracy',cv=3,verbose=1, n_jobs=-1, n_iter=50)\n",
    "svc_search4.fit(x_train4, y_train4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(probability=True, random_state=0),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.0001, 0.001, 0.01],\n",
       "                                        'degree': [1, 2, 3, 4, 5],\n",
       "                                        'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                                        'kernel': ['linear', 'rbf', 'poly']},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "print('Best parameters found:\\n', svc_search4.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % svc_search4.score(x_train4, y_train4))\n",
    "print(\" Test accuracy: %.4f\" % svc_search4.score(x_test4, y_test4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'kernel': 'poly', 'gamma': 100, 'degree': 2, 'C': 0.001}\n",
      "Train accuracy: 0.9988\n",
      " Test accuracy: 0.7904\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Next model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "network3 = MLPClassifier(max_iter=400, random_state=13, early_stopping=True)\n",
    "network3.fit(x_train3, y_train3)\n",
    "print(\"Train accuracy: %.4f\" % network3.score(x_train3, y_train3))\n",
    "print(\" Test accuracy: %.4f\" % network3.score(x_test3, y_test3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy: 0.9695\n",
      " Test accuracy: 0.7929\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "network3 = MLPClassifier(max_iter=400, random_state=13, early_stopping=True)\n",
    "gscv3 = RandomizedSearchCV(network3, param_distributions = try_params, cv=3, n_jobs=-1, n_iter=50)\n",
    "gscv3.fit(x_train3, y_train3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:289: UserWarning: The total space of parameters 24 is smaller than n_iter=50. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=MLPClassifier(early_stopping=True, max_iter=400,\n",
       "                                           random_state=13),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'activation': ['logistic', 'relu'],\n",
       "                                        'alpha': array([100. ,  10. ,   1. ,   0.1]),\n",
       "                                        'hidden_layer_sizes': [(50,), (100,),\n",
       "                                                               (128, 64, 32,\n",
       "                                                                8)]})"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "print('Best parameters found:\\n', gscv3.best_params_)\n",
    "print(\"Train accuracy: %.4f\" % gscv3.score(x_train3, y_train3))\n",
    "print(\" Test accuracy: %.4f\" % gscv3.score(x_test3, y_test3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters found:\n",
      " {'hidden_layer_sizes': (50,), 'alpha': 1.0, 'activation': 'relu'}\n",
      "Train accuracy: 0.9322\n",
      " Test accuracy: 0.7727\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "# network4 = MLPClassifier(max_iter=400, random_state=13, early_stopping=True)\n",
    "# network4.fit(x_train4, y_train4)\n",
    "# print(\"Train accuracy: %.4f\" % network4.score(x_train4, y_train4))\n",
    "# print(\" Test accuracy: %.4f\" % network4.score(x_test4, y_test4))\n",
    "# Train accuracy: 0.9403\n",
    "#  Test accuracy: 0.7790"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy: 0.9403\n",
      " Test accuracy: 0.7790\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}